{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygam import LinearGAM, s\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "def create_date_features(df):\n",
    "    df['DayOfYear'] = df.index.dayofyear\n",
    "    df['WeekOfYear'] = df.index.isocalendar().week\n",
    "    df['Month'] = df.index.month\n",
    "    df['Year'] = df.index.year\n",
    "\n",
    "    # Sine-cosine encoding for cyclical features\n",
    "    df['DayOfYear_sin'] = np.sin(2 * np.pi * df['DayOfYear'] / 365.25)\n",
    "    df['DayOfYear_cos'] = np.cos(2 * np.pi * df['DayOfYear'] / 365.25)\n",
    "    df['WeekOfYear_sin'] = np.sin(2 * np.pi * df['WeekOfYear'] / 52)\n",
    "    df['WeekOfYear_cos'] = np.cos(2 * np.pi * df['WeekOfYear'] / 52)\n",
    "    df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)\n",
    "    df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../../data/stock-market/ETFs/spy.us.txt')\n",
    "\n",
    "# Convert Date column to datetime and set it as the index\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Create lagged features\n",
    "for i in range(12, 37):\n",
    "    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        df[f'{col}_lag_{i}'] = df[col].shift(i)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Feature engineering: Extract date-related features and create sine-cosine embeddings\n",
    "df = create_date_features(df)\n",
    "\n",
    "# Define the target variable and features\n",
    "y = df['Close']\n",
    "features = [col for col in df.columns if col != 'Close']\n",
    "X = df[features]\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "end_date = df.index.max()\n",
    "test_start_date = end_date - pd.DateOffset(years=1)\n",
    "validation_start_date = test_start_date - pd.DateOffset(years=1)\n",
    "\n",
    "train_X = X[X.index < validation_start_date]\n",
    "train_y = y[y.index < validation_start_date]\n",
    "validation_X = X[(X.index >= validation_start_date) & (X.index < test_start_date)]\n",
    "validation_y = y[(y.index >= validation_start_date) & (y.index < test_start_date)]\n",
    "test_X = X[X.index >= test_start_date]\n",
    "test_y = y[y.index >= test_start_date]\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "train_X_normalized = X_normalized[X.index < validation_start_date]\n",
    "validation_X_normalized = X_normalized[(X.index >= validation_start_date) & (X.index < test_start_date)]\n",
    "test_X_normalized = X_normalized[X.index >= test_start_date]\n",
    "\n",
    "# PLS dimensionality reduction\n",
    "pls = PLSRegression(n_components=X.shape[1])  # Start with max components\n",
    "pls.fit(train_X_normalized, train_y)\n",
    "cumulative_variance = np.cumsum(np.sum(pls.x_scores_**2, axis=0) / np.sum(pls.x_scores_**2))\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1  # Number of components for 95% variance\n",
    "\n",
    "pls = PLSRegression(n_components=n_components)\n",
    "X_pls = pls.fit_transform(X_normalized, y)[0]\n",
    "train_X_pls = X_pls[:len(train_X)]\n",
    "validation_X_pls = X_pls[len(train_X):len(train_X)+len(validation_X)]\n",
    "test_X_pls = X_pls[len(train_X)+len(validation_X):]\n",
    "\n",
    "# RFE feature selection\n",
    "rfe = RFE(estimator=LinearRegression(), n_features_to_select=10)\n",
    "X_rfe = rfe.fit_transform(X_pls, y)\n",
    "train_X_rfe = X_rfe[:len(train_X)]\n",
    "validation_X_rfe = X_rfe[len(train_X):len(train_X)+len(validation_X)]\n",
    "test_X_rfe = X_rfe[len(train_X)+len(validation_X):]\n",
    "\n",
    "# Save train, validation, and test sets after PLS and RFE transformations\n",
    "pd.DataFrame(train_X_rfe).to_csv('train_X_pls_rfe.csv', index=False)\n",
    "pd.DataFrame(validation_X_rfe).to_csv('validation_X_pls_rfe.csv', index=False)\n",
    "pd.DataFrame(test_X_rfe).to_csv('test_X_pls_rfe.csv', index=False)\n",
    "train_y.to_csv('train_y_pls_rfe.csv', index=False)\n",
    "validation_y.to_csv('validation_y_pls_rfe.csv', index=False)\n",
    "test_y.to_csv('test_y_pls_rfe.csv', index=False)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Additive Model': LinearGAM(s(0, n_splines=20, lam=0.1) + \n",
    "                s(1, n_splines=20, lam=0.1) + \n",
    "                s(2, n_splines=20, lam=0.1) + \n",
    "                s(3, n_splines=20, lam=0.1) + \n",
    "                s(4, n_splines=20, lam=0.1)),\n",
    "    'SVR': SVR(kernel='linear', C=1, epsilon=0.1),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Neural Network': MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=2000, learning_rate_init=0.001, alpha=0.01),\n",
    "}\n",
    "\n",
    "# Decomposition (Additive Model)\n",
    "decomposition = seasonal_decompose(train_y, model='additive', period=365)\n",
    "train_y_detrended = train_y - decomposition.trend.dropna()\n",
    "\n",
    "# Train models and generate predictions using both training and validation data where applicable.\n",
    "predictions = {}\n",
    "for name, model in models.items():\n",
    "    if name == 'Linear Regression':\n",
    "        model.fit(train_X_rfe, train_y)\n",
    "        pred_test = model.predict(test_X_rfe)\n",
    "        pred_val = model.predict(validation_X_rfe)  # Predict on validation set for comparison later.\n",
    "    else:\n",
    "        model.fit(train_X_rfe if name != 'Additive Model' else train_X_rfe[:len(train_y_detrended)], \n",
    "                  train_y if name != 'Additive Model' else train_y_detrended)\n",
    "        pred_test = model.predict(test_X_rfe)\n",
    "        pred_val = model.predict(validation_X_rfe)  # Predict on validation set for comparison later.\n",
    "\n",
    "    predictions[name] = {\n",
    "        'Test': pred_test,\n",
    "        'Validation': pred_val,\n",
    "    }\n",
    "\n",
    "# Add actual values for comparison in predictions dictionary.\n",
    "for name in predictions.keys():\n",
    "    predictions[name]['Actual_Test'] = test_y.values\n",
    "\n",
    "# Calculate and display RMSE for each model on the test set.\n",
    "for name in predictions.keys():\n",
    "    rmse_test = np.sqrt(mean_squared_error(predictions[name]['Actual_Test'], predictions[name]['Test']))\n",
    "    print(f\"{name} Test RMSE: {rmse_test:.2f}\")\n",
    "\n",
    "# Plot actual vs. predicted prices for the last year.\n",
    "plt.figure(figsize=(12, 8))\n",
    "last_3_years = df.index[-1] - pd.DateOffset(years=3)\n",
    "df_last_3_years = df[df.index >= last_3_years]\n",
    "plt.plot(df_last_3_years.index, df_last_3_years['Close'], label='Close Price', color='blue')\n",
    "\n",
    "# Plot each model's predictions on the test set.\n",
    "for name in predictions.keys():\n",
    "    plt.plot(test_y.index, predictions[name]['Test'], label=f\"{name} Predictions\")\n",
    "\n",
    "plt.title(\"Actual vs Predicted Close Prices (Last Year with PLS and RFE)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Close Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
